# -*- coding: utf-8 -*-
"""scrapy mercado

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OP0z5i-F8_86LW6kbqcHH46OwYqojCzs
"""

from google.colab import drive
drive.mount('/content/drive')

!mkdir $'/content/documents'

pip install BeautifulSoup4

from bs4 import BeautifulSoup
import urllib.request
import os

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import re
import time
from datetime import datetime
import matplotlib.dates as mdates
import matplotlib.ticker as ticker
from urllib.request import urlopen
from bs4 import BeautifulSoup
import requests

headers = {'User-agent': 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36'}

URL= "https://www.amazon.es/s?k=calculus&i=stripbooks&__mk_es_ES=%C3%85M%C3%85%C5%BD%C3%95%C3%91&ref=nb_sb_noss_2"

page = urllib.request.urlopen(URL)
print(page)

soup = BeautifulSoup (page, "html.parser")
print(soup)

no_pages = 2

def get_data(pageNo):  
    headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0", "Accept-Encoding":"gzip, deflate", "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8", "DNT":"1","Connection":"close", "Upgrade-Insecure-Requests":"1"}

    r = requests.get('https://www.amazon.es/s?k=salmon+ahumado&__mk_es_ES=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=34M25D28SXC0E&sprefix=salmon%2Caps%2C188&ref=nb_sb_ss_ac-a-p_1_6'+str(pageNo)+'?ie=UTF8&pg='+str(pageNo), headers=headers)#, proxies=proxies)
    content = r.content
    soup = BeautifulSoup(content)
    #print(soup)

    alls = []
    for d in soup.findAll('div', attrs={'class':'a-section a-spacing-none aok-relative'}):
        #print(d)
        name = d.find('span', attrs={'class':'zg-text-center-align'})
        n = name.find_all('img', alt=True)
        #print(n[0]['alt'])
        author = d.find('a', attrs={'class':'a-size-small a-link-child'})
        rating = d.find('span', attrs={'class':'a-icon-alt'})
        users_rated = d.find('a', attrs={'class':'a-size-small a-link-normal'})
        price = d.find('span', attrs={'class':'p13n-sc-price'})

        all1=[]

        if name is not None:
            #print(n[0]['alt'])
            all1.append(n[0]['alt'])
        else:
            all1.append("unknown-product")

        if author is not None:
            #print(author.text)
            all1.append(author.text)
        elif author is None:
            author = d.find('span', attrs={'class':'a-size-small a-color-base'})
            if author is not None:
                all1.append(author.text)
            else:    
                all1.append('0')

        if rating is not None:
            #print(rating.text)
            all1.append(rating.text)
        else:
            all1.append('-1')

        if users_rated is not None:
            #print(price.text)
            all1.append(users_rated.text)
        else:
            all1.append('0')     

        if price is not None:
            #print(price.text)
            all1.append(price.text)
        else:
            all1.append('0')
        alls.append(all1)    
    return alls

p = soup.body.div.find_all('A')

p = soup.body.div.find_all('A')

print (soup)

results = []
for i in range(1, no_pages+1):
    results.append(get_data(i))
flatten = lambda l: [item for sublist in l for item in sublist]
df = pd.DataFrame(flatten(results),columns=['Book Name','Author','Rating','Customers_Rated', 'Price'])
df.to_csv('amazon_products.csv', index=False, encoding='utf-8')

df = pd.read_csv("amazon_products.csv")



df.shape

df.head(4)

df['Rating'] = df['Rating'].apply(lambda x: x.split()[0])

df['Rating'] = pd.to_numeric(df['Rating'])

df["Price"] = df["Price"].str.replace('$', '')

df["Price"] = df["Price"].str.replace(',', '')

df['Price'] = df['Price'].apply(lambda x: x.split('.')[0])

df['Price'] = df['Price'].astype(int)

df["Customers_Rated"] = df["Customers_Rated"].str.replace(',', '')

df['Customers_Rated'] = pd.to_numeric(df['Customers_Rated'], errors='ignore')

df.head()

df.dtypes

df.replace(str(0), np.nan, inplace=True)
df.replace(0, np.nan, inplace=True)

count_nan = len(df) - df.count()
count_nan

df = df.dropna()

data = df.sort_values(["Price"], axis=0, ascending=False)[:15]

data

from bokeh.models import ColumnDataSource
from bokeh.transform import dodge
import math
from bokeh.io import curdoc
curdoc().clear()
from bokeh.io import push_notebook, show, output_notebook
from bokeh.layouts import row
from bokeh.plotting import figure
from bokeh.transform import factor_cmap
from bokeh.models import Legend
output_notebook()

p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=550, title="Authors Highest Priced Book", toolbar_location=None, tools="")

p.vbar(x=data.iloc[:,1], top=data.iloc[:,4], width=0.9)

p.xgrid.grid_line_color = None
p.y_range.start = 0
p.xaxis.major_label_orientation = math.pi/2

show(p)

data = df[df['Customers_Rated'] > 1000]

data = data.sort_values(['Rating'],axis=0, ascending=False)[:15]

data

p = figure(x_range=data.iloc[:,0], plot_width=800, plot_height=600, title="Top Rated Books with more than 1000 Customers Rating", toolbar_location=None, tools="")

p.vbar(x=data.iloc[:,0], top=data.iloc[:,2], width=0.9)

p.xgrid.grid_line_color = None
p.y_range.start = 0
p.xaxis.major_label_orientation = math.pi/2

p = figure(x_range=data.iloc[:,1], plot_width=800, plot_height=600, title="Top Rated Books with more than 1000 Customers Rating", toolbar_location=None, tools="")

p.vbar(x=data.iloc[:,1], top=data.iloc[:,2], width=0.9)

p.xgrid.grid_line_color = None
p.y_range.start = 0
p.xaxis.major_label_orientation = math.pi/2

data = df.sort_values(["Customers_Rated"], axis=0, ascending=False)[:20]

from bokeh.transform import factor_cmap
from bokeh.models import Legend
from bokeh.palettes import Dark2_5 as palette
import itertools
from bokeh.palettes import d3
#colors has a list of colors which can be used in plots
colors = itertools.cycle(palette)

palette = d3['Category20'][20]

index_cmap = factor_cmap('Author', palette=palette,
                         factors=data["Author"])

p = figure(plot_width=700, plot_height=700, title = "Top Authors: Rating vs. Customers Rated")
p.scatter('Rating','Customers_Rated',source=data,fill_alpha=0.6, fill_color=index_cmap,size=20,legend='Author')
p.xaxis.axis_label = 'RATING'
p.yaxis.axis_label = 'CUSTOMERS RATED'
p.legend.location = 'top_left'

show(p)

a = ["salmon"]
url_str = input("pescado")
url = ["https://www.amazon.es/s?k=pescado&i=grocery&__mk_es_ES=%C3%85M%C3%85%C5%BD%C3%95%C3%91&ref=nb_sb_noss"]

words = url_str.split()
var = len(words)

if var == 1:
	url = "https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&field-keywords=" + words[0]

if var == 2:
	url = "https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&field-keywords=" + words[0] + "+" + words[1]

elif var == 3:
	url = "https://www.amazon.com/s/ref=nb_sb_noss_1?url=search-alias%3Daps&field-keywords=" + words[0] + "+" + words[1] + "+" + words[2]

# Add header
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36'}

r = requests.get(url, headers=headers)

filename = "products.csv"
f = open(filename, "w", encoding='utf-8')

from bs4 import BeautifulSoup
import re # import Regular expression operations module
import requests
from time import gmtime, strftime

strftime("%Y-%m-%d %H:%M:%S", gmtime())

headers ="Asin, Name," + "Price : " + strftime("%Y-%m-%d %H:%M:%S", gmtime()) + ", Number of Reviews\n"
f.write(headers)

containers1 = soup.findAll("li", {"class":"s-result-item s-result-card-for-container a-declarative celwidget "})
print("containers style 1: ", len(containers1))

containers2 = soup.findAll("li", {"class":"s-result-item s-result-card-for-container s-carded-grid celwidget "})
print("containers style 2: ", len(containers2))

sponsored_containers = soup.findAll("li", {"class":"s-result-item celwidget AdHolder"}) 
print("containers style 3 sponsored: ", len(sponsored_containers))

common_containers = soup.findAll("li", {"class":"s-result-item celwidget "})  
print("containers style 4 common: ", len(common_containers))

#check for special style
containers3 = soup.findAll("li", {"class":"s-result-item s-col-span-12 celwidget "})
print("containers style 5 special", len(containers3))

for container in sponsored_containers:
	# Product Asin
	asin = (container["data-asin"])

	# Product Name
	try:
		title_container = container.findAll("a", {"class":"a-link-normal s-access-detail-page s-color-twister-title-link a-text-normal"}) 
		name = title_container[0]["title"]
	except:
		name = "N/A"

#Number of reviews
	num_review_container = container.findAll("a", {"class":"a-size-small a-link-normal a-text-normal"})
	try:
		if (len(num_review_container) > 1):
			num_reviews = num_review_container[1].text
		else:
			num_reviews = num_review_container[0].text
	except:
		num_reviews = "0"

	#try:
	#	num_review2 = num_review_container[1].text.strip()
	#	print(num_review2)
	# except list index out of range:
	#	num_review2 = 0;

	f.write(asin + ',' + name.replace(",", "|") + ',' + price.replace("$", "") + "," + num_reviews.replace(",", "") + "\n")

f.close()